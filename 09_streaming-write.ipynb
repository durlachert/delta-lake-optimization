{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62078030-a0f6-482e-abdb-7d5feedf19e9",
   "metadata": {},
   "source": [
    "# Stream Write Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3089de-5f7c-4e0b-ac1c-9d10b9f77a30",
   "metadata": {},
   "source": [
    "This notebook performs the following operations:\n",
    "\n",
    "- Read data from Apache Kafka Stream\n",
    "- Write data to a Delta Lake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86078d-d407-4fac-b624-3f3c06fb0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f692aec7-6b60-4a1f-8631-431030aacf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/03 09:05:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Special Apache Spark configuration with reduced resources for two applications\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StreamWrite\") \\\n",
    "    .master(\"spark://192.168.0.144:7077\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.hive.metastore.uris\", \"thrift://192.168.0.144:9083\") \\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionURL\", \"jdbc:mysql://192.168.0.144:3306/metastore_db\") \\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionDriverName\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionUserName\", \"lh\") \\\n",
    "    .config(\"spark.hadoop.javax.jdo.option.ConnectionPassword\", os.getenv('MYSQL', 'Default_Value')) \\\n",
    "    .config(\"spark.jars\", \"/usr/local/spark/jars/delta-storage-3.2.0.jar,/usr/local/spark/jars/delta-spark_2.12-3.2.0.jar,/usr/local/spark/jars/kafka-clients-3.5.1.jar,/usr/local/spark/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar, /usr/local/spark/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar, /usr/local/spark/jars/commons-pool2-2.11.1.jar\")    \\\n",
    "    .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.HDFSLogStore\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.driver.cores\", \"6\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://192.168.0.144:9000\") \\\n",
    "    .config(\"spark.databricks.delta.clusteredTable.enableClusteringTablePreview\", \"true\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", \"1000\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"2\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9acd7-43ef-4331-8a1d-910f71bbf65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DoubleType\n",
    "\n",
    "kafka_bootstrap_servers = \"192.168.0.145:9092\"\n",
    "kafka_topic = \"delta\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"value\", DoubleType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"event_id\", LongType(), True),\n",
    "    StructField(\"actor_id\", LongType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"month\", IntegerType(), True),\n",
    "    StructField(\"day\", IntegerType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"location_id\", IntegerType(), True),\n",
    "    StructField(\"department_id\", IntegerType(), True),\n",
    "    StructField(\"campaign_id\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "kafka_stream = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "kafka_stream = kafka_stream.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "df = kafka_stream.select(from_json(col(\"value\"), schema).alias(\"data\"))\n",
    "\n",
    "\n",
    "df_flat = df.select(\n",
    "    col(\"data.timestamp\").cast(\"timestamp\").alias(\"timestamp\"),\n",
    "    col(\"data.value\").alias(\"value\"),\n",
    "    col(\"data.country\").alias(\"country\"),\n",
    "    col(\"data.event_id\").alias(\"event_id\"),\n",
    "    col(\"data.actor_id\").alias(\"actor_id\"),\n",
    "    col(\"data.year\").alias(\"year\"),\n",
    "    col(\"data.month\").alias(\"month\"),\n",
    "    col(\"data.day\").alias(\"day\"),\n",
    "    col(\"data.product_id\").alias(\"product_id\"),\n",
    "    col(\"data.location_id\").alias(\"location_id\"),\n",
    "    col(\"data.department_id\").alias(\"department_id\"),\n",
    "    col(\"data.campaign_id\").alias(\"campaign_id\"),\n",
    "    col(\"data.customer_id\").alias(\"customer_id\")\n",
    ")\n",
    "\n",
    "query = df_flat.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"checkpointLocation\", \"/path/to/checkpoint/delta\") \\\n",
    "    .option(\"mergeSchema\", \"true\")  \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start(\"/datalake/stream/kafka_delta_target\")  \n",
    "\n",
    "query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab46d48-47a1-44f0-aa57-43cf2bf1fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- event_id: long (nullable = true)\n",
      " |-- actor_id: long (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- location_id: integer (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- campaign_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------+--------+----+------+--------+----------+-----------+-------------+-----------+-----------+\n",
      "|               value|     country|event_id|actor_id|year| month|     day|product_id|location_id|department_id|campaign_id|customer_id|\n",
      "+--------------------+------------+--------+--------+----+------+--------+----------+-----------+-------------+-----------+-----------+\n",
      "|  0.9441410408078205|    Thailand|  176134|    4297|2024|202406|20240622|         1|          1|            1|          1|          1|\n",
      "|   0.632545944339363|       Italy|  905906|    3525|2024|202406|20240622|         2|          2|            2|          2|          2|\n",
      "|  0.6625826329665729|   Indonesia|  117763|    1957|2024|202406|20240622|         3|          3|            3|          3|          3|\n",
      "|  0.8917914736796113|    Maldives|  686811|    7807|2024|202406|20240622|         4|          4|            4|          4|          4|\n",
      "|  0.8537482285593957|       Egypt|  194755|    9290|2024|202406|20240622|         5|          5|            5|          5|          5|\n",
      "|  0.4019497634495055|South Africa|  104009|    1321|2024|202406|20240622|         6|          6|            6|          6|          6|\n",
      "| 0.45033744378762275|   Australia|  764436|    1208|2024|202406|20240622|         7|          7|            7|          7|          7|\n",
      "|  0.7408707469295507|         USA|  649769|     499|2024|202406|20240622|         8|          8|            8|          8|          8|\n",
      "|  0.6259426349897106|         USA|  214481|    7466|2024|202406|20240622|         9|          9|            9|          9|          9|\n",
      "| 0.36814462206189436|    Thailand|  177485|    1697|2024|202406|20240622|        10|         10|           10|         10|         10|\n",
      "|  0.3923706960432911|   Singapore|  595438|    3917|2024|202406|20240622|         1|          1|            1|          1|          1|\n",
      "|0.023532159486757576|    Thailand|  234570|    7388|2024|202406|20240622|         2|          2|            2|          2|          2|\n",
      "|  0.6956644440825729|      Turkey|  743027|    7221|2024|202406|20240622|         3|          3|            3|          3|          3|\n",
      "| 0.27910620253547436|   Argentina|  504790|    3551|2024|202406|20240622|         4|          4|            4|          4|          4|\n",
      "|  0.7511452321173381|   Singapore|  968059|    4294|2024|202406|20240622|         5|          5|            5|          5|          5|\n",
      "| 0.31841940296514026| New Zealand|  878154|    9537|2024|202406|20240622|         6|          6|            6|          6|          6|\n",
      "|  0.5753747027744274|   Indonesia|  554983|    7256|2024|202406|20240622|         7|          7|            7|          7|          7|\n",
      "|  0.6228272029743753|  Bangladesh|  826738|    2831|2024|202406|20240622|         8|          8|            8|          8|          8|\n",
      "|  0.9446546145710626|      Bhutan|  805643|    3267|2024|202406|20240622|         9|          9|            9|          9|          9|\n",
      "|  0.2201109355545806|   Sri Lanka|   67036|    5961|2024|202406|20240622|        10|         10|           10|         10|         10|\n",
      "+--------------------+------------+--------+--------+----+------+--------+----------+-----------+-------------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "delta_table_path = \"/datalake/stream/kafka_delta_target\"\n",
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "\n",
    "selected_columns_df = df.select(\n",
    "    \"value\",\n",
    "    \"country\",\n",
    "    \"event_id\",\n",
    "    \"actor_id\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"product_id\",\n",
    "    \"location_id\",\n",
    "    \"department_id\",\n",
    "    \"campaign_id\",\n",
    "    \"customer_id\"\n",
    ")\n",
    "\n",
    "selected_columns_df.printSchema()\n",
    "selected_columns_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
